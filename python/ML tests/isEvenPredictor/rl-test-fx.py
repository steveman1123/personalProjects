#original code generated by chatgpt, modified
#attempt to recognize if the next bar will close much higher or lower or within some set range of the previous bar (eg if the previous bar closes at 1.017 and the minimum change is 0.01, then the next bar could be considered an increase if it closes at >=1.027, a decrease if it closes at <=1.007, or a no-change if it's anywhere in between)

import random,json,time

startTime = time.time()

# Define the dataset
datafile = "datasets/eurusd-hour-close.txt"
with open(datafile,'r') as f:
  data = f.readlines()
  data = [float(e) for e in data]

datalen = 1000 #length of dataset to use
offset = random.randint(0,len(data)-datalen) #window of the overall dataset to use
data = data[-(offset+datalen):-offset] #subset of data to use

print(datafile)
print("dataset size:",len(data))

#minimum difference between data points to reward (instead of strictly greater than or less than, it must be greather than or less than this amount difference (eg if this is 0.1, previous point is 1.0, then the next point must be 0.9 or 1.1 in order to be rewarded))
mindiff = 0.001 #0.0001=1 pip

# Initialize the Q-table
q_table = {}
for i in range(len(data)):
  q_table[i] = {'increase': 0, 'decrease': 0, 'no-change':0}

# Set the hyperparameters
alpha = 0.1 #TODO: what does this mean?
gamma = 0.6 #TODO: what does this mean?
epsilon = 0.1 #liklihood of making a random choice (opposed to an informed choice)

# Define the reward function
def reward(state, action):
  if action == 'increase' and data[state+1] >= data[state]+mindiff :
    return 1
  elif action == 'decrease' and data[state+1] <= data[state]-mindiff :
    return 1
  elif action == 'no-change' and data[state]-mindiff<data[state+1]<data[state]+mindiff:
    return 1
  else:
    return 0

# Run the Q-learning algorithm
episodes = 500 #number of episodes to train

print("training progress:")
print("_"*100) #for progress bar clarity
for i in range(episodes):
  #display the progress bar
  if(int(i/(episodes/100))==i/(episodes/100)): print("#",end="",flush=True)

  #init the state to be at the beginning and reset the 'done' flag
  state = 0
  done = False

  while not done:
    #randomly choose an increase or decrease number 10% of the time (or whatever the epsilon is set to)
    if random.uniform(0, 1) < epsilon:
      action = random.choice(['increase', 'decrease','no-change'])
    else:
      #get the choice values of the current state
      q_values = q_table[state]
      #choose the most likely value as the action
      action = max(q_values, key=q_values.get)

    #give us the reward!
    r = reward(state, action)
    

    #move on to the next state
    next_state = state + 1
    
    #if it's the last state in the episode
    if next_state == len(data) - 1:
      #set the 'done' flag
      done = True
      #TODO: figure out why this is doing what it is
      q_table[state][action] += alpha * (r - q_table[state][action])
    else:
      #it's not the last state yet
      #TODO: what is it doing here?
      q_next_values = q_table[next_state]
      #
      max_q_next_value = max(q_next_values.values())
      #
      q_table[state][action] += alpha * (r + gamma * max_q_next_value - q_table[state][action])
      #increment the state
      state = next_state

# Use the learned Q-table to predict the next number
print()

#set the latest test point/state
latesttestpoint = q_table[len(data)-2]
#if the 'increase' has the highest score
if(max(latesttestpoint,key=latesttestpoint.get)=='increase'):
  print(f'The next number ({data[-1]}) should increase (from {data[-2]})')
#if the 'decrease' has the highest score
elif(max(latesttestpoint,key=latesttestpoint.get)=='decrease'):
  print(f'The next number ({data[-1]}) should decrease (from {data[-2]})')
#if the 'no-change' has the highest score
elif(max(latesttestpoint,key=latesttestpoint.get)=='no-change'):
  print(f'The next number ({data[-1]}) should have a small change (between {round(data[-2]-mindiff,5)} and {round(data[-2]+mindiff,5)})')
#it should never be able to reach this unless a new action type is added
else:
  print("yo wtf?")
  exit()



#calculate some predicition values

#which ones were predicted to increase
predicted_increase = [int(max(q_table[e],key=q_table[e].get)=='increase') for e in q_table][:-1]
#which ones actually increased
actual_increase = [int(data[i]>=data[i-1]+mindiff) for i in range(len(data[1:]))]

#which ones were predicted to decrease
predicted_decrease = [int(max(q_table[e],key=q_table[e].get)=='decrease') for e in q_table][:-1]
#which ones actually decreased
actual_decrease = [int(data[i]<=data[i-1]-mindiff) for i in range(len(data[1:]))]
#which ones were predicted to have no-change
predicted_no_change = [int(max(q_table[e],key=q_table[e].get)=='no-change') for e in q_table][:-1]
#which ones actually had no-change
actual_no_change = [int((data[i-1]-mindiff)<(data[i])<(data[i-1]+mindiff)) for i in range(len(data[1:]))]


#how many were correctly predicted to decrease
correct_decrease_predictions = sum([predicted_decrease[i]==actual_decrease[i+1] for i in range(len(predicted_decrease)-1)])
#how many predictions were made to decrease
total_decrease_predictions = len(predicted_decrease)-1

#how many were correctly predicted to increase
correct_increase_predictions = sum([predicted_increase[i]==actual_increase[i+1] for i in range(len(predicted_increase)-1)])
#how many predictions were made to increase
total_increase_predictions = len(predicted_increase)-1

#how many were correctly predicted to have no-change
correct_no_change_predictions = sum([predicted_no_change[i]==actual_no_change[i+1] for i in range(len(predicted_no_change)-1)])
#how many predictions were made to have no-change
total_no_change_predictions = len(predicted_no_change)-1

#display prediction results
print("correct_decrease_predictions:",correct_decrease_predictions,"total_decrease_predictions:",total_decrease_predictions,sep="\t")
print("correct_increase_predictions:",correct_increase_predictions,"total_increase_predictions:",total_increase_predictions,sep="\t")
print("correct_no_change_predictions:",correct_no_change_predictions,"total_no_change_predictions:",total_no_change_predictions,sep="\t")
print("avg accuracy:",round(sum([correct_increase_predictions/total_increase_predictions,correct_decrease_predictions/total_decrease_predictions,correct_no_change_predictions/total_no_change_predictions])/3,5))

print()
print("run time (s):",round(time.time()-startTime,5))